"""
è³‡æ–™åŒ¯å‡ºæœå‹™
æä¾› CSV æ ¼å¼çš„çµ±è¨ˆè³‡æ–™åŒ¯å‡ºåŠŸèƒ½
"""
import csv
import io
from typing import List, Dict, Any, Optional
from datetime import datetime
from ..database import db
from ..models.schemas import QuestionStatus
from ..utils.datetime_helper import format_datetime


class ExportService:
    """è³‡æ–™åŒ¯å‡ºæœå‹™é¡åˆ¥"""
    
    async def export_questions_to_csv(
        self,
        course_id: str,
        class_id: Optional[str] = None,
        # =========== ğŸ”¥ æ–°å¢åƒæ•¸ ğŸ”¥ ===========
        cluster_id: Optional[str] = None,
        # ====================================
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None
    ) -> str:
        """
        åŒ¯å‡ºæå•è³‡æ–™ç‚º CSV æ ¼å¼ (åŒ…å« AI åˆ†ææ¬„ä½)
        """
        database = db.get_db()
        collection = database["questions"]
        
        # å»ºç«‹æŸ¥è©¢æ¢ä»¶
        query: Dict[str, Any] = {"course_id": course_id}
        
        if class_id:
            query["class_id"] = class_id

        # =========== ğŸ”¥ æ–°å¢ç¯©é¸é‚è¼¯ ğŸ”¥ ===========
        if cluster_id:
            query["cluster_id"] = cluster_id
        # ========================================
        
        if start_date or end_date:
            query["created_at"] = {}
            if start_date:
                query["created_at"]["$gte"] = start_date
            if end_date:
                query["created_at"]["$lte"] = end_date
        
        # å–å¾—è³‡æ–™
        cursor = collection.find(query).sort("created_at", -1)
        questions = await cursor.to_list(length=None)
        
        # å»ºç«‹ CSV
        output = io.StringIO()
        writer = csv.writer(output)
        
        # å¯«å…¥æ¨™é¡Œåˆ— (æ–°å¢ AI ç›¸é—œæ¬„ä½)
        writer.writerow([
            "æå•ID",
            "å»è­˜åˆ¥åŒ–ä»£è™Ÿ",
            "æå•å…§å®¹",
            "ç‹€æ…‹",
            "AIèšé¡ID",
            "é›£åº¦åˆ†æ•¸",
            "é›£åº¦ç­‰ç´š",
            "é—œéµå­—",
            # =========== ğŸ”¥ æ–°å¢æ¨™é¡Œ ğŸ”¥ ===========
            "AIå›ç­”è‰ç¨¿",
            "AIæ‘˜è¦",
            "æƒ…ç·’åˆ†æ•¸",
            # ====================================
            "æ˜¯å¦å·²åˆä½µ",
            "åˆä½µè‡³Q&A ID",
            "å»ºç«‹æ™‚é–“",
            "æ›´æ–°æ™‚é–“"
        ])
        
        # å¯«å…¥è³‡æ–™åˆ—
        for q in questions:
            writer.writerow([
                str(q["_id"]),
                q.get("pseudonym", ""),
                q.get("question_text", ""),
                q.get("status", ""),
                q.get("cluster_id", ""),
                q.get("difficulty_score", ""),
                q.get("difficulty_level", ""),
                ", ".join(q.get("keywords", [])),
                # =========== ğŸ”¥ æ–°å¢è³‡æ–™æ¬„ä½ ğŸ”¥ ===========
                q.get("ai_response_draft", ""),
                q.get("ai_summary", ""),
                q.get("sentiment_score", ""),
                # ========================================
                "æ˜¯" if q.get("is_merged", False) else "å¦",
                q.get("merged_to_qa_id", ""),
                format_datetime(q.get("created_at")),
                format_datetime(q.get("updated_at"))
            ])
        
        csv_content = output.getvalue()
        output.close()
        
        return csv_content

    # =========== ğŸ”¥ æ–°å¢æ–¹æ³•ï¼šåŒ¯å‡ºèšé¡å ±è¡¨ ğŸ”¥ ===========
    async def export_clusters_to_csv(
        self,
        course_id: str
    ) -> str:
        """
        åŒ¯å‡º AI èšé¡ä¸»é¡Œåˆ†æå ±è¡¨
        """
        database = db.get_db()
        collection = database["questions"]
        
        # ä½¿ç”¨èšåˆç®¡é“çµ±è¨ˆèšé¡è³‡è¨Š
        pipeline = [
            {
                "$match": {
                    "course_id": course_id,
                    "cluster_id": {"$ne": None}
                }
            },
            {
                "$group": {
                    "_id": "$cluster_id",
                    "count": {"$sum": 1},
                    "avg_difficulty": {"$avg": "$difficulty_score"},
                    "keywords": {"$push": "$keywords"}
                }
            },
            {
                "$sort": {"count": -1}
            }
        ]
        
        results = await collection.aggregate(pipeline).to_list(length=None)
        
        # å»ºç«‹ CSV
        output = io.StringIO()
        writer = csv.writer(output)
        
        # å¯«å…¥æ¨™é¡Œ
        writer.writerow([
            "èšé¡ID (ä¸»é¡Œ)",
            "æå•æ•¸é‡",
            "å¹³å‡é›£åº¦",
            "ç†±é–€é—œéµå­— (Top 5)"
        ])
        
        # è™•ç†è³‡æ–™
        for result in results:
            # çµ±è¨ˆè©²èšé¡ä¸‹çš„ç†±é–€é—œéµå­—
            all_keywords = []
            for kw_list in result.get("keywords", []):
                all_keywords.extend(kw_list)
            
            keyword_freq = {}
            for kw in all_keywords:
                keyword_freq[kw] = keyword_freq.get(kw, 0) + 1
            
            top_keywords = sorted(
                keyword_freq.items(),
                key=lambda x: x[1],
                reverse=True
            )[:5]
            top_keywords_str = ", ".join([k[0] for k in top_keywords])
            
            writer.writerow([
                result["_id"],
                result["count"],
                f"{result.get('avg_difficulty', 0):.2f}",
                top_keywords_str
            ])
            
        csv_content = output.getvalue()
        output.close()
        
        return csv_content
    # =================================================

    async def export_qas_to_csv(
        self,
        course_id: str,
        class_id: Optional[str] = None
    ) -> str:
        """
        åŒ¯å‡º Q&A è³‡æ–™ç‚º CSV æ ¼å¼
        """
        database = db.get_db()
        collection = database["qas"]
        
        # å»ºç«‹æŸ¥è©¢æ¢ä»¶
        query: Dict[str, Any] = {"course_id": course_id}
        
        if class_id:
            query["$or"] = [
                {"class_id": class_id},
                {"class_id": None}
            ]
        
        # å–å¾—è³‡æ–™
        cursor = collection.find(query).sort("created_at", -1)
        qas = await cursor.to_list(length=None)
        
        # å»ºç«‹ CSV
        output = io.StringIO()
        writer = csv.writer(output)
        
        # å¯«å…¥æ¨™é¡Œåˆ—
        writer.writerow([
            "Q&A ID",
            "å•é¡Œ",
            "å›ç­”",
            "åˆ†é¡",
            "æ¨™ç±¤",
            "æ˜¯å¦ç™¼å¸ƒ",
            "ç™¼å¸ƒæ™‚é–“",
            "ç›¸é—œæå•æ•¸é‡",
            "å»ºç«‹è€…",
            "å»ºç«‹æ™‚é–“"
        ])
        
        # å¯«å…¥è³‡æ–™åˆ—
        for qa in qas:
            writer.writerow([
                str(qa["_id"]),
                qa.get("question", ""),
                qa.get("answer", ""),
                qa.get("category", ""),
                ", ".join(qa.get("tags", [])),
                "æ˜¯" if qa.get("is_published", False) else "å¦",
                format_datetime(qa.get("publish_date")),
                len(qa.get("related_question_ids", [])),
                qa.get("created_by", ""),
                format_datetime(qa.get("created_at"))
            ])
        
        csv_content = output.getvalue()
        output.close()
        
        return csv_content
    
    async def export_statistics_to_csv(
        self,
        course_id: str,
        class_id: Optional[str] = None
    ) -> str:
        """
        åŒ¯å‡ºçµ±è¨ˆè³‡æ–™ç‚º CSV æ ¼å¼
        """
        database = db.get_db()
        collection = database["questions"]
        
        # å»ºç«‹æŸ¥è©¢æ¢ä»¶
        query: Dict[str, Any] = {"course_id": course_id}
        if class_id:
            query["class_id"] = class_id
        
        # çµ±è¨ˆå„ç‹€æ…‹çš„æå•æ•¸é‡
        status_pipeline = [
            {"$match": query},
            {
                "$group": {
                    "_id": "$status",
                    "count": {"$sum": 1}
                }
            }
        ]
        status_stats = await collection.aggregate(status_pipeline).to_list(length=None)
        
        # çµ±è¨ˆå„èšé¡çš„æå•æ•¸é‡
        cluster_pipeline = [
            {"$match": {**query, "cluster_id": {"$ne": None}}},
            {
                "$group": {
                    "_id": "$cluster_id",
                    "count": {"$sum": 1},
                    "avg_difficulty": {"$avg": "$difficulty_score"}
                }
            },
            {"$sort": {"count": -1}}
        ]
        cluster_stats = await collection.aggregate(cluster_pipeline).to_list(length=None)
        
        # çµ±è¨ˆé›£åº¦åˆ†å¸ƒ
        difficulty_pipeline = [
            {"$match": {**query, "difficulty_level": {"$ne": None}}},
            {
                "$group": {
                    "_id": "$difficulty_level",
                    "count": {"$sum": 1}
                }
            }
        ]
        difficulty_stats = await collection.aggregate(difficulty_pipeline).to_list(length=None)
        
        # å»ºç«‹ CSV
        output = io.StringIO()
        writer = csv.writer(output)
        
        # ç¬¬ä¸€éƒ¨åˆ†ï¼šç‹€æ…‹çµ±è¨ˆ
        writer.writerow(["=== æå•ç‹€æ…‹çµ±è¨ˆ ==="])
        writer.writerow(["ç‹€æ…‹", "æ•¸é‡"])
        for stat in status_stats:
            writer.writerow([stat["_id"], stat["count"]])
        writer.writerow([])
        
        # ç¬¬äºŒéƒ¨åˆ†ï¼šèšé¡çµ±è¨ˆ
        writer.writerow(["=== AI èšé¡çµ±è¨ˆ ==="])
        writer.writerow(["èšé¡ID", "æå•æ•¸é‡", "å¹³å‡é›£åº¦"])
        for stat in cluster_stats:
            writer.writerow([
                stat["_id"],
                stat["count"],
                f"{stat.get('avg_difficulty', 0):.2f}"
            ])
        writer.writerow([])
        
        # ç¬¬ä¸‰éƒ¨åˆ†ï¼šé›£åº¦åˆ†å¸ƒçµ±è¨ˆ
        writer.writerow(["=== é›£åº¦åˆ†å¸ƒçµ±è¨ˆ ==="])
        writer.writerow(["é›£åº¦ç­‰ç´š", "æ•¸é‡"])
        for stat in difficulty_stats:
            writer.writerow([stat["_id"], stat["count"]])
        
        csv_content = output.getvalue()
        output.close()
        
        return csv_content


# å…¨åŸŸæœå‹™å¯¦ä¾‹
export_service = ExportService()