"""
è³‡æ–™åŒ¯å‡ºæœå‹™
æä¾› CSV æ ¼å¼çš„çµ±è¨ˆè³‡æ–™åŒ¯å‡ºåŠŸèƒ½
"""
import csv
import io
from typing import List, Dict, Any, Optional
from datetime import datetime
from ..database import db
from ..models.schemas import QuestionStatus
from ..utils.datetime_helper import format_datetime


class ExportService:
    """è³‡æ–™åŒ¯å‡ºæœå‹™é¡åˆ¥"""
    
    async def export_questions_to_csv(
        self,
        course_id: str,
        class_id: Optional[str] = None,
        cluster_id: Optional[str] = None,
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None
    ) -> str:
        """
        åŒ¯å‡ºæå•è³‡æ–™ç‚º CSV æ ¼å¼ (åŒ…å« AI åˆ†ææ¬„ä½)
        """
        database = db.get_db()
        collection = database["questions"]
        
        # å»ºç«‹å¤šç¶­åº¦æŸ¥è©¢æ¢ä»¶
        query: Dict[str, Any] = {"course_id": course_id, "status": {"$ne": "DELETED"}}
        
        if class_id:
            query["class_id"] = class_id

        if cluster_id:
            query["cluster_id"] = cluster_id
        
        # æ™‚é–“å€é–“éæ¿¾
        if start_date or end_date:
            query["created_at"] = {}
            if start_date:
                query["created_at"]["$gte"] = start_date
            if end_date:
                query["created_at"]["$lte"] = end_date
        
        # å–å¾—è³‡æ–™
        cursor = collection.find(query).sort("created_at", -1)
        questions = await cursor.to_list(length=None)
        
        # å»ºç«‹ CSV
        output = io.StringIO()
        writer = csv.writer(output)
        
        # å¯«å…¥æ¨™é¡Œåˆ—
        writer.writerow([
            "æå•ID", "å»è­˜åˆ¥åŒ–ä»£è™Ÿ", "æå•å…§å®¹", "ç‹€æ…‹", "AIèšé¡ID",
            "é›£åº¦åˆ†æ•¸", "é›£åº¦ç­‰ç´š", "é—œéµå­—", "AIå›ç­”è‰ç¨¿", "AIæ‘˜è¦",
            "æƒ…ç·’åˆ†æ•¸", "æ˜¯å¦å·²åˆä½µ", "åˆä½µè‡³Q&A ID", "å»ºç«‹æ™‚é–“", "æ›´æ–°æ™‚é–“"
        ])
        
        # å¯«å…¥è³‡æ–™åˆ—
        for q in questions:
            # ğŸ”¥ é˜²å‘†ï¼šç¢ºä¿ keywords ä¸æ˜¯ Noneï¼Œé¿å… join å ±éŒ¯
            keywords = q.get("keywords") or []
            
            writer.writerow([
                str(q["_id"]),
                q.get("pseudonym", ""),
                q.get("question_text", ""),
                q.get("status", ""),
                q.get("cluster_id", ""),
                q.get("difficulty_score", ""),
                q.get("difficulty_level", ""),
                ", ".join(keywords),
                q.get("ai_response_draft", ""),
                q.get("ai_summary", ""),
                q.get("sentiment_score", ""),
                "æ˜¯" if q.get("is_merged", False) else "å¦",
                q.get("merged_to_qa_id", ""),
                format_datetime(q.get("created_at")) if q.get("created_at") else "",
                format_datetime(q.get("updated_at")) if q.get("updated_at") else ""
            ])
        
        csv_content = output.getvalue()
        output.close()
        
        return csv_content


    async def export_clusters_to_csv(self, course_id: str) -> str:
        """
        åŒ¯å‡º AI èšé¡ä¸»é¡Œåˆ†æå ±è¡¨
        """
        database = db.get_db()
        # ğŸ”¥ ä¿®æ­£ï¼šç›´æ¥è®€å– clusters è³‡æ–™è¡¨ï¼Œæ‰èƒ½æ‹¿åˆ° AI ç”Ÿæˆçš„ä¸»é¡Œæ¨™ç±¤èˆ‡æ‘˜è¦ï¼
        collection = database["clusters"]
        
        cursor = collection.find({"course_id": course_id}).sort("question_count", -1)
        clusters = await cursor.to_list(length=None)
        
        # å»ºç«‹ CSV
        output = io.StringIO()
        writer = csv.writer(output)
        
        # å¯«å…¥æ¨™é¡Œ
        writer.writerow([
            "èšé¡ID", "ä¸»é¡Œæ¨™ç±¤ (Topic)", "ç¶œåˆæ‘˜è¦ (Summary)", 
            "åŒ…å«æå•æ•¸", "å¹³å‡é›£åº¦", "é—œéµå­—", "æ˜¯å¦äººå·¥é–å®š"
        ])
        
        # è™•ç†è³‡æ–™
        for c in clusters:
            keywords = c.get("keywords") or []
            writer.writerow([
                str(c["_id"]),
                c.get("topic_label", ""),
                c.get("summary", ""),
                c.get("question_count", 0),
                f"{c.get('avg_difficulty', 0):.2f}",
                ", ".join(keywords),
                "æ˜¯" if c.get("is_locked", False) else "å¦"
            ])
            
        csv_content = output.getvalue()
        output.close()
        
        return csv_content


    async def export_qas_to_csv(
        self,
        course_id: str,
        class_id: Optional[str] = None
    ) -> str:
        """
        åŒ¯å‡º Q&A è³‡æ–™ç‚º CSV æ ¼å¼
        """
        database = db.get_db()
        collection = database["qas"]
        
        query: Dict[str, Any] = {"course_id": course_id}
        if class_id:
            query["$or"] = [{"class_id": class_id}, {"class_id": None}]
        
        cursor = collection.find(query).sort("created_at", -1)
        qas = await cursor.to_list(length=None)
        
        output = io.StringIO()
        writer = csv.writer(output)
        
        writer.writerow([
            "Q&A ID", "å•é¡Œ", "å›ç­”", "åˆ†é¡", "æ¨™ç±¤", "æ˜¯å¦ç™¼å¸ƒ",
            "ç™¼å¸ƒæ™‚é–“", "ç›¸é—œæå•æ•¸é‡", "å»ºç«‹è€…", "å»ºç«‹æ™‚é–“"
        ])
        
        for qa in qas:
            tags = qa.get("tags") or []
            related = qa.get("related_question_ids") or []
            writer.writerow([
                str(qa["_id"]),
                qa.get("question", ""),
                qa.get("answer", ""),
                qa.get("category", ""),
                ", ".join(tags),
                "æ˜¯" if qa.get("is_published", False) else "å¦",
                format_datetime(qa.get("publish_date")) if qa.get("publish_date") else "",
                len(related),
                qa.get("created_by", ""),
                format_datetime(qa.get("created_at")) if qa.get("created_at") else ""
            ])
        
        csv_content = output.getvalue()
        output.close()
        return csv_content
    
    async def export_statistics_to_csv(
        self,
        course_id: str,
        class_id: Optional[str] = None
    ) -> str:
        """
        åŒ¯å‡ºçµ±è¨ˆè³‡æ–™ç‚º CSV æ ¼å¼
        """
        database = db.get_db()
        collection = database["questions"]
        
        query: Dict[str, Any] = {"course_id": course_id, "status": {"$ne": "DELETED"}}
        if class_id:
            query["class_id"] = class_id
        
        # 1. çµ±è¨ˆå„ç‹€æ…‹
        status_pipeline = [
            {"$match": query},
            {"$group": {"_id": "$status", "count": {"$sum": 1}}}
        ]
        status_stats = await collection.aggregate(status_pipeline).to_list(length=None)
        
        # 2. çµ±è¨ˆé›£åº¦åˆ†å¸ƒ
        difficulty_pipeline = [
            {"$match": {**query, "difficulty_level": {"$ne": None}}},
            {"$group": {"_id": {"$toUpper": "$difficulty_level"}, "count": {"$sum": 1}}}
        ]
        difficulty_stats = await collection.aggregate(difficulty_pipeline).to_list(length=None)
        
        # å»ºç«‹ CSV
        output = io.StringIO()
        writer = csv.writer(output)
        
        writer.writerow(["=== æå•ç‹€æ…‹çµ±è¨ˆ ==="])
        writer.writerow(["ç‹€æ…‹", "æ•¸é‡"])
        for stat in status_stats:
            writer.writerow([stat["_id"], stat["count"]])
        writer.writerow([])
        
        writer.writerow(["=== é›£åº¦åˆ†å¸ƒçµ±è¨ˆ ==="])
        writer.writerow(["é›£åº¦ç­‰ç´š", "æ•¸é‡"])
        for stat in difficulty_stats:
            writer.writerow([stat["_id"], stat["count"]])
        
        csv_content = output.getvalue()
        output.close()
        return csv_content


# å…¨åŸŸæœå‹™å¯¦ä¾‹
export_service = ExportService()